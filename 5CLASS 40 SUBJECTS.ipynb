{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4222,"status":"ok","timestamp":1708441432580,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"WQPZcvWgVsrO","outputId":"d297ecc1-b8a7-4769-b30f-90562b221c7d"},"outputs":[],"source":["import torch\n","\n","if torch.cuda.is_available():\n","    print('CUDA-enabled GPU found.')\n","else:\n","    print('No GPU found. Training will be carried out on CPU, which might be '\n","          'slower.\\n\\nIf running on Google Colab, you can request a GPU runtime by'\n","          ' clicking\\n`Runtime/Change runtime type` in the top bar menu, then '\n","          'selecting \\'GPU\\'\\nunder \\'Hardware accelerator\\'.')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30573,"status":"ok","timestamp":1708441465691,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"tWSdQ3DZ25xO","outputId":"f5df04b4-8d97-413c-8f66-aaeaead54e6e"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29649,"status":"ok","timestamp":1708441495306,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"9p-Sq7QBV5XH","outputId":"eb5136fb-e62a-4b49-f12f-3a780c3e8f7e"},"outputs":[],"source":["!pip install mne\n","!pip install torch\n","!pip install matplotlib\n","!pip install scikit-learn\n","!pip install pandas"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"IJG87sw2V_68"},"outputs":[],"source":["import os\n","import copy\n","import mne\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","\n","\n","# enable GPU\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ecVav98kGK00"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6930499,"status":"ok","timestamp":1708319185995,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"HIyyffoLWEtV","outputId":"12c29ada-e23a-4d8b-ffdb-a038cd02b349"},"outputs":[],"source":["\n","# import mne\n","# from mne.datasets.sleep_physionet.age import fetch_data\n","\n","# subjects, recordings = range(83), [1, 2]\n","\n","# fnames = fetch_data(subjects=subjects, recording=recordings, on_missing='warn')\n","# mne.set_log_level('ERROR')  # To avoid flooding the cell outputs with messages"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Xqfk-V9r65iu"},"outputs":[],"source":["# fnames = [\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4001E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4001EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4002E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4002EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4011E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4011EH-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4012E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4012EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4021E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4021EH-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4022E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4022EJ-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4031E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4031EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4032E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4032EP-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4041E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4041EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4042E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4042EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4051E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4051EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4052E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4052EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4061E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4061EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4062E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4062EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4071E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4071EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4072E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4072EH-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4081E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4081EC-Hypnogram.edf'),\n","#     ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4082E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4082EP-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4091E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4091EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4092E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4092EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4101E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4101EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4102E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4102EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4111E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4111EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4112E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4112EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4121E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4121EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4122E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4122EV-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4131E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4131EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4141E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4141EU-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4142E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4142EU-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4151E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4151EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4152E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4152EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4161E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4161EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4162E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4162EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4171E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4171EU-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4172E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4172EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4181E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4181EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4182E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4182EC-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4191E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4191EP-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4192E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4192EV-Hypnogram.edf'),\n","# ('/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4201E0-PSG.edf', '/content/drive/MyDrive/physionet.org/files/sleep-edfx/1.0.0/sleep-cassette/SC4201EC-Hypnogram.edf')\n","\n","\n","\n","\n","# ]\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["\n","fnames = [\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4001E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4001EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4002E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4002EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4011E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4011EH-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4012E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4012EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4021E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4021EH-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4022E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4022EJ-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4031E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4031EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4032E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4032EP-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4041E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4041EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4042E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4042EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4051E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4051EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4052E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4052EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4061E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4061EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4062E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4062EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4071E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4071EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4072E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4072EH-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4081E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4081EC-Hypnogram.edf'),\n","    ('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4082E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4082EP-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4091E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4091EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4092E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4092EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4101E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4101EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4102E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4102EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4111E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4111EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4112E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4112EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4121E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4121EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4122E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4122EV-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4131E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4131EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4141E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4141EU-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4142E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4142EU-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4151E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4151EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4152E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4152EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4161E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4161EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4162E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4162EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4171E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4171EU-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4172E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4172EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4181E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4181EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4182E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4182EC-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4191E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4191EP-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4192E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4192EV-Hypnogram.edf'),\n","('../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4201E0-PSG.edf', '../../data_set/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4201EC-Hypnogram.edf')\n","\n","]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fnames"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"7iwZrn0pWSgE"},"outputs":[],"source":["def load_sleep_physionet_raw(raw_fname, annot_fname, load_eeg_only=True,\n","                             crop_wake_mins=30):\n","\n","    mapping = {'EOG horizontal': 'eog',\n","               'Resp oro-nasal': 'misc',\n","               'EMG submental': 'misc',\n","               'Temp rectal': 'misc',\n","               'Event marker': 'misc'}\n","    exclude = mapping.keys() if load_eeg_only else ()\n","\n","    raw = mne.io.read_raw_edf(raw_fname, exclude=exclude)\n","    annots = mne.read_annotations(annot_fname)\n","    raw.set_annotations(annots, emit_warning=False)\n","    if not load_eeg_only:\n","        raw.set_channel_types(mapping)\n","\n","    if crop_wake_mins > 0:  # Cut start and end Wake periods\n","        # Find first and last sleep stages\n","        mask = [x[-1] in ['1', '2', '3', '4', 'R']\n","                for x in annots.description]\n","        sleep_event_inds = np.where(mask)[0]\n","\n","        # Crop raw\n","        max_time = (raw.n_times - 1) / raw.info['sfreq']\n","        #print(max_time)\n","        tmin = annots[int(sleep_event_inds[0])]['onset'] - \\\n","               crop_wake_mins * 60\n","        tmax = annots[int(sleep_event_inds[-1])]['onset'] + \\\n","               crop_wake_mins * 60\n","        if tmin >= 0 and tmax <= max_time:   # data preprocessing removing tmax (%s) which are grater than or equal to the max\n","            raw.crop(tmin=tmin, tmax=tmax)\n","        else:\n","            pass\n","\n","    # Rename EEG channels\n","    ch_names = {i: i.replace('EEG ', '')\n","                for i in raw.ch_names if 'EEG' in i}\n","    mne.rename_channels(raw.info, ch_names)\n","\n","    # Save subject and recording information in raw.info\n","    basename = os.path.basename(raw_fname)\n","    subj_nb, rec_nb = int(basename[3:5]), int(basename[5])\n","    raw.info['subject_info'] = {'id': subj_nb, 'rec_id': rec_nb}\n","\n","    return raw"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# def load_sleep_physionet_raw(raw_fname, annot_fname, load_eeg_only=True,\n","#                              crop_wake_mins=30):\n","\n","#     # Mapping and exclude variables\n","#     mapping = {'EOG horizontal': 'eog',\n","#                'Resp oro-nasal': 'misc',\n","#                'EMG submental': 'misc',\n","#                'Temp rectal': 'misc',\n","#                'Event marker': 'misc'}\n","#     exclude = mapping.keys() if load_eeg_only else ()\n","#     print(\"Mapping:\", mapping)\n","#     print(\"Exclude Channels:\", exclude)\n","\n","#     # Load raw data\n","#     raw = mne.io.read_raw_edf(raw_fname, exclude=exclude)\n","#     annots = mne.read_annotations(annot_fname)\n","#     print(\"Annotations:\", annots)\n","#     raw.set_annotations(annots, emit_warning=False)\n","    \n","#     if not load_eeg_only:\n","#         raw.set_channel_types(mapping)\n","#         print(\"Channel types set for non-EEG channels.\")\n","\n","#     if crop_wake_mins > 0:  # Cut start and end Wake periods\n","#         # Find first and last sleep stages\n","#         mask = [x[-1] in ['1', '2', '3', '4', 'R']\n","#                 for x in annots.description]\n","#         sleep_event_inds = np.where(mask)[0]\n","#         print(\"Sleep Event Indices:\", sleep_event_inds)\n","\n","#         # Crop raw data\n","#         max_time = (raw.n_times - 1) / raw.info['sfreq']\n","#         print(\"Max Time (seconds):\", max_time)\n","#         tmin = annots[int(sleep_event_inds[0])]['onset'] - crop_wake_mins * 60\n","#         tmax = annots[int(sleep_event_inds[-1])]['onset'] + crop_wake_mins * 60\n","#         print(\"Crop Start (tmin):\", tmin)\n","#         print(\"Crop End (tmax):\", tmax)\n","\n","#         if tmin >= 0 and tmax <= max_time:   \n","#             raw.crop(tmin=tmin, tmax=tmax)\n","#             print(f\"Data cropped from {tmin} to {tmax} seconds.\")\n","#         else:\n","#             print(\"No cropping applied due to invalid tmin or tmax.\")\n","\n","#     # Rename EEG channels\n","#     ch_names = {i: i.replace('EEG ', '')\n","#                 for i in raw.ch_names if 'EEG' in i}\n","#     print(\"Renamed Channel Names:\", ch_names)\n","#     mne.rename_channels(raw.info, ch_names)\n","\n","#     # Save subject and recording information in raw.info\n","#     basename = os.path.basename(raw_fname)\n","#     subj_nb, rec_nb = int(basename[3:5]), int(basename[5])\n","#     raw.info['subject_info'] = {'id': subj_nb, 'rec_id': rec_nb}\n","#     print(\"Subject Info:\", raw.info['subject_info'])\n","\n","#     return raw\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6133,"status":"ok","timestamp":1708442322533,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"bJjBG6WxkVI5","outputId":"811d859c-ac42-4bf9-cc8d-52e32aca6640"},"outputs":[],"source":["#data_loading\n","\n","raws=[load_sleep_physionet_raw(f[0], f[1]) for f in fnames]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6988,"status":"ok","timestamp":1708442331749,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"iavRfuUAkXi1","outputId":"54f9e2b6-313e-4278-b8c5-815750ac1049"},"outputs":[],"source":["# Plot a recording as a sanity check\n","raws[1].plot();\n","raws[0].plot();"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":51243,"status":"ok","timestamp":1708442385864,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"woLmxGB4kaeh","outputId":"4cd9f979-851e-4c0a-94a8-1febccf0ead6"},"outputs":[],"source":["l_freq, h_freq = None, 30\n","\n","for raw in raws:\n","    raw.load_data().filter(l_freq, h_freq)  # filtering happens in-place\n","\n","\n","# Plot the power spectrum of a recording as sanity check\n","raws[0].plot_psd();"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import mne\n","\n","# Load your raw data\n","# raws = [...]  # Assuming raws is a list of MNE Raw objects\n","\n","l_freq, h_freq = None, 30\n","\n","# Filter the data\n","for raw in raws:\n","    raw.load_data().filter(l_freq, h_freq)  # filtering happens in-place\n","\n","# Plot the power spectrum of a recording as sanity check\n","fig, ax = plt.subplots(figsize=(10, 6))\n","raws[0].plot_psd(ax=ax, fmax=30, show=False)  # Plotting the PSD of the first raw data\n","\n","# Define frequency bands and colors\n","bands = {\n","    'Delta (0-4 Hz)': (0, 4),\n","    'Theta (4-8 Hz)': (4, 8),\n","    'Low Alpha (8-10 Hz)': (8, 10),\n","    'High Alpha (10-12 Hz)': (10, 12),\n","    'Low Beta (12-18 Hz)': (12, 18),\n","    'High Beta (18-30 Hz)': (18, 30)\n","}\n","\n","# Add shaded regions for frequency bands\n","for band, (low, high) in bands.items():\n","    ax.axvspan(low, high, color=np.random.rand(3,), alpha=0.3, label=band)  # Random color for each band\n","\n","# Add labels and legend\n","ax.set_title('Power Spectrum with Frequency Bands')\n","ax.set_xlabel('Frequency (Hz)')\n","ax.set_ylabel('Power Spectral Density (dB/Hz)')\n","ax.legend(loc='upper right')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"rRAi8iH8k33Y"},"outputs":[],"source":["# function to extract 30-s windows\n","\n","def extract_epochs(raw, chunk_duration=30.):\n","\n","    annotation_desc_2_event_id = {\n","        'Sleep stage W': 1,\n","        'Sleep stage 1': 2,\n","        'Sleep stage 2': 3,\n","        'Sleep stage 3': 4,\n","        'Sleep stage 4': 4,\n","        'Sleep stage R': 5}\n","\n","    events, _ = mne.events_from_annotations(\n","        raw, event_id=annotation_desc_2_event_id,\n","        chunk_duration=chunk_duration)\n","\n","    # create a new event_id that unifies stages 3 and 4\n","    event_id = {\n","        'Sleep stage W': 1,\n","        'Sleep stage 1': 2,\n","        'Sleep stage 2': 3,\n","        'Sleep stage 3/4': 4,\n","        'Sleep stage R': 5}\n","\n","    tmax = 30. - 1. / raw.info['sfreq']  # tmax in included\n","    picks = mne.pick_types(raw.info, eeg=True, eog=True)\n","    epochs = mne.Epochs(raw=raw, events=events, picks=picks, preload=True,\n","                        event_id=event_id, tmin=0., tmax=tmax, baseline=None)\n","\n","    return epochs.get_data(), epochs.events[:, 2] - 1"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# def extract_epochs(raw, chunk_duration=30.):\n","\n","#     # Mapping of annotation descriptions to event IDs\n","#     annotation_desc_2_event_id = {\n","#         'Sleep stage W': 1,\n","#         'Sleep stage 1': 2,\n","#         'Sleep stage 2': 3,\n","#         'Sleep stage 3': 4,\n","#         'Sleep stage 4': 4,\n","#         'Sleep stage R': 5}\n","#     print(\"Annotation to Event ID Mapping:\", annotation_desc_2_event_id)\n","\n","#     # Extract events from annotations\n","#     events, _ = mne.events_from_annotations(\n","#         raw, event_id=annotation_desc_2_event_id,\n","#         chunk_duration=chunk_duration)\n","#     print(\"Events:\", events)\n","    \n","#     # Create a unified event ID for stages 3 and 4\n","#     event_id = {\n","#         'Sleep stage W': 1,\n","#         'Sleep stage 1': 2,\n","#         'Sleep stage 2': 3,\n","#         'Sleep stage 3/4': 4,\n","#         'Sleep stage R': 5}\n","#     print(\"Unified Event ID Mapping:\", event_id)\n","\n","#     # Calculate tmax based on the raw data's sampling frequency\n","#     tmax = 30. - 1. / raw.info['sfreq']  # tmax is inclusive\n","#     print(\"tmax:\", tmax)\n","\n","#     # Pick channels (EEG and EOG)\n","#     picks = mne.pick_types(raw.info, eeg=True, eog=True)\n","#     print(\"Picked Channels:\", picks)\n","\n","#     # Create epochs\n","#     epochs = mne.Epochs(raw=raw, events=events, picks=picks, preload=True,\n","#                         event_id=event_id, tmin=0., tmax=tmax, baseline=None)\n","#     print(\"Epochs:\", epochs)\n","\n","#     # Return the epochs data and labels (adjust labels by subtracting 1)\n","#     data = epochs.get_data()\n","#     labels = epochs.events[:, 2] - 1\n","#     print(\"Epoch Data Shape:\", data.shape)\n","#     print(\"Epoch Labels:\", labels)\n","\n","#     return data, labels\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"-T7da3BMuD6M"},"outputs":[],"source":["# wrap arounfd around pytorch dataset class\n","from torch.utils.data import Dataset, ConcatDataset\n","\n","class EpochsDataset(Dataset):\n","\n","    def __init__(self,epochs_data, epochs_labels, subj_nb=None, rec_nb=None, transform =None):\n","        assert len(epochs_data) == len(epochs_labels)\n","        self.epochs_data =epochs_data\n","        self.epochs_labels = epochs_labels\n","        self.subj_nb = subj_nb\n","        self.rec_nb = rec_nb\n","        self.transform = transform\n","    def __len__(self):\n","        return len(self.epochs_labels)\n","    def __getitem__(self,idx):\n","        X, y = self.epochs_data[idx], self.epochs_labels[idx]\n","        if self.transform is not None:\n","            X = self.transform(X)\n","        X = torch.as_tensor(X[None, ...])\n","        return X, y\n","\n","#Standard scaling of data\n","\n","def scale(X):\n","\n","    X -= np.mean(X, axis=1, keepdims=True)\n","    return X / np.std(X, axis=1, keepdims=True)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import torch\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","class EpochsDataset(Dataset):\n","\n","    def __init__(self, epochs_data, epochs_labels, subj_nb=None, rec_nb=None, transform=None):\n","        # Ensure the lengths of data and labels match\n","        assert len(epochs_data) == len(epochs_labels)\n","        self.epochs_data = epochs_data\n","        self.epochs_labels = epochs_labels\n","        self.subj_nb = subj_nb\n","        self.rec_nb = rec_nb\n","        self.transform = transform\n","        # Print all the initialization variables\n","        print(\"Initialized EpochsDataset\")\n","        print(\"Epochs Data Shape:\", epochs_data.shape)\n","        print(\"Epochs Labels Shape:\", epochs_labels.shape)\n","        print(\"Subject Number:\", subj_nb)\n","        print(\"Recording Number:\", rec_nb)\n","        print(\"Transform Function:\", transform)\n","\n","    def __len__(self):\n","        # Print the length of the dataset when called\n","        length = len(self.epochs_labels)\n","        print(\"Dataset Length:\", length)\n","        return length\n","\n","    def __getitem__(self, idx):\n","        # Print the index being accessed\n","        print(\"Fetching data for index:\", idx)\n","        X, y = self.epochs_data[idx], self.epochs_labels[idx]\n","        print(\"Raw Data (X):\", X)\n","        print(\"Label (y):\", y)\n","\n","        # Apply transform if provided\n","        if self.transform is not None:\n","            print(\"Applying transform to data\")\n","            X = self.transform(X)\n","        else:\n","            print(\"No transform applied\")\n","        \n","        # Add a new axis and convert to tensor\n","        X = torch.as_tensor(X[None, ...])\n","        print(\"Transformed Data (X) Tensor Shape:\", X.shape)\n","\n","        return X, y\n","\n","# Standard scaling of data\n","def scale(X):\n","    print(\"Original Data (X):\", X)\n","    \n","    # Calculate the mean and standard deviation\n","    mean_X = np.mean(X, axis=1, keepdims=True)\n","    std_X = np.std(X, axis=1, keepdims=True)\n","    \n","    print(\"Mean of X:\", mean_X)\n","    print(\"Standard Deviation of X:\", std_X)\n","\n","    # Perform standard scaling\n","    X -= mean_X\n","    scaled_X = X / std_X\n","    print(\"Scaled Data (X):\", scaled_X)\n","    \n","    return scaled_X\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":175893,"status":"ok","timestamp":1708442561728,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"ut1lw3PI5Vgw","outputId":"f1f37541-4983-4df5-f2d5-7269f41320e8"},"outputs":[],"source":["\n","raws = [load_sleep_physionet_raw(f[0], f[1]) for f in fnames]\n","\n","# If you want to test with only two datasets\n","raws_exc = [raws[1]]  # Remove the dataset you want to exclude\n","all_datasets = [EpochsDataset(*extract_epochs(raw), subj_nb=raw.info['subject_info']['id'], rec_nb=raw.info['subject_info']['rec_id'], transform=scale)\n","                for i, raw in enumerate(raws) if i not in raws_exc]\n","\n","# Concatenate into a single dataset\n","dataset = ConcatDataset(all_datasets)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ZraRelxAxzW5"},"outputs":[],"source":["from sklearn.model_selection import LeavePGroupsOut\n","\n","\n","def pick_recordings(dataset, subj_rec_nbs):\n","\n","    pick_idx = []\n","    for subj_nb, rec_nb in subj_rec_nbs:\n","        for i, ds in enumerate(dataset.datasets):\n","            if (ds.subj_nb == subj_nb) and (ds.rec_nb == rec_nb):\n","                pick_idx.append(i)\n","\n","    remaining_idx = np.setdiff1d(\n","        range(len(dataset.datasets)), pick_idx)\n","\n","    pick_ds = ConcatDataset([dataset.datasets[i] for i in pick_idx])\n","    if len(remaining_idx) > 0:\n","        remaining_ds = ConcatDataset(\n","            [dataset.datasets[i] for i in remaining_idx])\n","    else:\n","        remaining_ds = None\n","\n","    return pick_ds, remaining_ds\n","\n","\n","def train_test_split(dataset, n_groups, split_by='subj_nb'):\n","\n","    groups = [getattr(ds, split_by) for ds in dataset.datasets]\n","    train_idx, test_idx = next(\n","        LeavePGroupsOut(n_groups).split(X=groups, groups=groups))\n","\n","    train_ds = ConcatDataset([dataset.datasets[i] for i in train_idx])\n","    test_ds = ConcatDataset([dataset.datasets[i] for i in test_idx])\n","\n","    return train_ds, test_ds"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# from sklearn.model_selection import LeavePGroupsOut\n","# import numpy as np\n","# from torch.utils.data import ConcatDataset\n","\n","# def pick_recordings(dataset, subj_rec_nbs):\n","\n","#     print(f\"Input subject and recording numbers: {subj_rec_nbs}\")\n","#     pick_idx = []\n","    \n","#     # Iterate over all subject and recording numbers\n","#     for subj_nb, rec_nb in subj_rec_nbs:\n","#         print(f\"Checking for Subject: {subj_nb}, Recording: {rec_nb}\")\n","#         for i, ds in enumerate(dataset.datasets):\n","#             if (ds.subj_nb == subj_nb) and (ds.rec_nb == rec_nb):\n","#                 pick_idx.append(i)\n","#                 print(f\"Match found at index {i}\")\n","    \n","#     print(f\"Picked indices: {pick_idx}\")\n","\n","#     # Find the remaining indices\n","#     remaining_idx = np.setdiff1d(range(len(dataset.datasets)), pick_idx)\n","#     print(f\"Remaining indices: {remaining_idx}\")\n","\n","#     # Create picked dataset and remaining dataset\n","#     pick_ds = ConcatDataset([dataset.datasets[i] for i in pick_idx])\n","#     print(f\"Picked Dataset: {pick_ds}\")\n","\n","#     if len(remaining_idx) > 0:\n","#         remaining_ds = ConcatDataset([dataset.datasets[i] for i in remaining_idx])\n","#         print(f\"Remaining Dataset: {remaining_ds}\")\n","#     else:\n","#         remaining_ds = None\n","#         print(\"No remaining datasets.\")\n","\n","#     return pick_ds, remaining_ds\n","\n","# def train_test_split(dataset, n_groups, split_by='subj_nb'):\n","\n","#     print(f\"Splitting dataset by: {split_by} with {n_groups} groups\")\n","    \n","#     # Extract groups based on the split_by attribute\n","#     groups = [getattr(ds, split_by) for ds in dataset.datasets]\n","#     print(f\"Groups: {groups}\")\n","\n","#     # Perform LeavePGroupsOut split\n","#     splitter = LeavePGroupsOut(n_groups)\n","#     train_idx, test_idx = next(splitter.split(X=groups, groups=groups))\n","    \n","#     print(f\"Train indices: {train_idx}\")\n","#     print(f\"Test indices: {test_idx}\")\n","\n","#     # Create train and test datasets\n","#     train_ds = ConcatDataset([dataset.datasets[i] for i in train_idx])\n","#     test_ds = ConcatDataset([dataset.datasets[i] for i in test_idx])\n","\n","#     print(f\"Train Dataset: {train_ds}\")\n","#     print(f\"Test Dataset: {test_ds}\")\n","\n","#     return train_ds, test_ds\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"O1Q73bKGx6CR"},"outputs":[],"source":["# We seed the random number generators to make our splits reproducible\n","torch.manual_seed(103)\n","np.random.seed(103)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_kFmVSU5d3k"},"outputs":[],"source":["# Use recording 1 of subjects 0-19 as test set\n","test_recs = [(subj_nb, rec_nb)  #\n","             for subj_nb, rec_nb in zip(range(20), [1] * 10)]\n","test_ds, train_ds = pick_recordings(dataset, test_recs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1708442561733,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"GRjOnjRv7lzn","outputId":"a76ab9d1-28eb-4c9f-f306-542ef1f65b7c"},"outputs":[],"source":["# Split remaining recordings into training and validation sets\n","n_subjects_valid = max(1, int(len(train_ds.datasets) * 0.2))\n","train_ds, valid_ds = train_test_split(train_ds, n_subjects_valid, split_by='subj_nb')\n","\n","print('Number of examples in each set:')\n","print(f'Training: {len(train_ds)}')\n","print(f'Validation: {len(valid_ds)}')\n","print(f'Test: {len(test_ds)}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","# Data for each set\n","datasets = ['Training', 'Validation', 'Test']\n","examples_count = [len(train_ds), len(valid_ds), len(test_ds)]\n","\n","# Create a custom colormap from blue to yellow\n","colors = sns.color_palette(\"coolwarm\", as_cmap=False, n_colors=len(datasets))\n","\n","# Create the bar plot\n","plt.figure(figsize=(8, 5))\n","sns.barplot(x=datasets, y=examples_count, palette=colors)\n","\n","# Add labels and title\n","plt.xlabel('Dataset')\n","plt.ylabel('Number of Examples')\n","plt.title('Number of Examples in Each Dataset')\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"elapsed":5870,"status":"ok","timestamp":1708442567573,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"zT9C0Wo07no_","outputId":"872acfdf-6d65-4e53-8fae-68f8a75189cd"},"outputs":[],"source":["classes_mapping = {0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}\n","y_train = pd.Series([y for _, y in train_ds]).map(classes_mapping)\n","ax = y_train.value_counts().plot(kind='barh')\n","ax.set_xlabel('Number of training examples');\n","ax.set_ylabel('Sleep stage');"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","\n","# Example data and mapping (assuming train_ds is already defined)\n","classes_mapping = {0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}\n","y_train = pd.Series([y for _, y in train_ds]).map(classes_mapping)\n","\n","# Create the horizontal bar plot\n","fig, ax = plt.subplots(figsize=(10, 6))\n","value_counts = y_train.value_counts()\n","\n","# Define a color palette (one color for each bar)\n","colors = ['mediumseagreen', 'lightcoral', 'steelblue', 'goldenrod', 'orchid']\n","\n","# Plot with different colors for each bar\n","bars = ax.barh(value_counts.index, value_counts.values, color=colors, edgecolor='black', hatch='')\n","\n","# Set labels and title with custom styling\n","ax.set_xlabel('Number of Training Examples', fontsize=12, color='black')\n","ax.set_ylabel('Sleep Stage', fontsize=12, color='black')\n","ax.set_title('Distribution of Training Examples by Sleep Stage', fontsize=14, color='black')\n","\n","# Customize the plot background and grid\n","ax.set_facecolor('lightgray')\n","ax.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')\n","\n","# Add bar labels with numeric values outside the bars\n","for bar in bars:\n","    width = bar.get_width()\n","    ax.annotate(f'{width}',\n","                xy=(width, bar.get_y() + bar.get_height() / 2),\n","                xytext=(5, 0),  # 5 points horizontal offset to avoid touching the rectangle\n","                textcoords=\"offset points\",\n","                ha='left', va='center', fontsize=10, color='black')\n","\n","# Add a legend without the rectangle (only the name \"Training Examples\")\n","# Create a blank Rectangle and add it to the legend\n","blank_patch = Rectangle((0, 0), 1, 1, fill=False, edgecolor='none', visible=False)\n","ax.legend([blank_patch], ['Training Examples'], loc='upper right', fontsize=10)\n","\n","# Adjust layout for better appearance\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":124,"status":"ok","timestamp":1708442567579,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"Fa8l4KRb7sxv","outputId":"f976659b-986c-4868-8035-75d9306334f4"},"outputs":[],"source":["# Computing class weight\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","train_y = np.concatenate([ds.epochs_labels for ds in train_ds.datasets])\n","class_weights = compute_class_weight('balanced', classes=np.unique(train_y), y=train_y)\n","print(class_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Define the class names and their corresponding weights\n","class_names = ['N3', 'N1', 'R', 'W', 'N2']\n","# class_weights = np.array([0.2, 0.3, 0.1, 0.1, 0.3])  # Replace with your actual class weights\n","class_weights = [0.95528734, 3.6621547,  0.47941416, 1.57213163, 1.04365282]\n","# Define colors for the pie chart\n","colors = plt.cm.Paired.colors[:len(class_names)]\n","\n","# Plotting the pie chart with class weights\n","plt.figure(figsize=(8, 8))\n","patches, texts, autotexts = plt.pie(class_weights, labels=class_names, autopct='%1.1f%%', colors=colors, startangle=90)\n","\n","# Adding title\n","plt.title('Class Weights Distribution (Percentage)', fontsize=14)\n","\n","# Adding legend\n","plt.legend(patches, [f'Class {cls}' for cls in class_names], loc=\"best\")\n","\n","# Beautifying the chart\n","for text in autotexts:\n","    text.set_color('white')  # Make the percentage text color white for better readability\n","\n","# Show the pie chart\n","plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n","plt.show()\n"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["# echo \"# task\" >> README.md\n","# git init\n","# git add README.md\n","# git commit -m \"first commit\"\n","# git branch -M main\n","# git remote add origin https://github.com/mitaliptl-005/task.git\n","# # git push -u origin main"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"d6OraJqB7woJ"},"outputs":[],"source":["from torch import nn\n","\n","\n","class SleepStagerChambon2018(nn.Module):\n","\n","    def __init__(self, n_channels, sfreq, n_conv_chs=8, time_conv_size_s=0.5,\n","                 max_pool_size_s=0.125, n_classes=5, input_size_s=30,\n","                 dropout=0.25):\n","        super().__init__()\n","\n","        time_conv_size = int(time_conv_size_s * sfreq)\n","        max_pool_size = int(max_pool_size_s * sfreq)\n","        input_size = int(input_size_s * sfreq)\n","        pad_size = time_conv_size // 2\n","        self.n_channels = n_channels\n","        len_last_layer = self._len_last_layer(\n","            n_channels, input_size, max_pool_size, n_conv_chs)\n","\n","        if n_channels > 1:\n","            self.spatial_conv = nn.Conv2d(1, n_channels, (n_channels, 1))\n","\n","        self.feature_extractor = nn.Sequential(\n","            nn.Conv2d(\n","                1, n_conv_chs, (1, time_conv_size), padding=(0, pad_size)),\n","            nn.ReLU(),\n","            nn.MaxPool2d((1, max_pool_size)),\n","            nn.Conv2d(\n","                n_conv_chs, n_conv_chs, (1, time_conv_size),\n","                padding=(0, pad_size)),\n","            nn.ReLU(),\n","            nn.MaxPool2d((1, max_pool_size))\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Dropout(dropout),\n","            nn.Linear(len_last_layer, n_classes)\n","        )\n","\n","    @staticmethod\n","    def _len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs):\n","        return n_channels * (input_size // (max_pool_size ** 2)) * n_conv_chs\n","\n","    def forward(self, x):\n","\n","        if self.n_channels > 1:\n","            x = self.spatial_conv(x)\n","            x = x.transpose(1, 2)\n","\n","        x = self.feature_extractor(x)\n","        return self.fc(x.flatten(start_dim=1))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# from torch import nn\n","# import torch\n","\n","# class SleepStagerChambon2018(nn.Module):\n","\n","#     def __init__(self, n_channels, sfreq, n_conv_chs=8, time_conv_size_s=0.5,\n","#                  max_pool_size_s=0.125, n_classes=5, input_size_s=30,\n","#                  dropout=0.25):\n","#         super().__init__()\n","\n","#         time_conv_size = int(time_conv_size_s * sfreq)\n","#         max_pool_size = int(max_pool_size_s * sfreq)\n","#         input_size = int(input_size_s * sfreq)\n","#         pad_size = time_conv_size // 2\n","#         self.n_channels = n_channels\n","#         print(f\"Initialization - n_channels: {n_channels}, sfreq: {sfreq}, \"\n","#               f\"time_conv_size: {time_conv_size}, max_pool_size: {max_pool_size}, \"\n","#               f\"input_size: {input_size}, pad_size: {pad_size}\")\n","\n","#         len_last_layer = self._len_last_layer(\n","#             n_channels, input_size, max_pool_size, n_conv_chs)\n","#         print(f\"Length of the last layer: {len_last_layer}\")\n","\n","#         if n_channels > 1:\n","#             self.spatial_conv = nn.Conv2d(1, n_channels, (n_channels, 1))\n","#             print(f\"Spatial Conv Layer created: {self.spatial_conv}\")\n","\n","#         self.feature_extractor = nn.Sequential(\n","#             nn.Conv2d(1, n_conv_chs, (1, time_conv_size), padding=(0, pad_size)),\n","#             nn.ReLU(),\n","#             nn.MaxPool2d((1, max_pool_size)),\n","#             nn.Conv2d(n_conv_chs, n_conv_chs, (1, time_conv_size), padding=(0, pad_size)),\n","#             nn.ReLU(),\n","#             nn.MaxPool2d((1, max_pool_size))\n","#         )\n","#         print(f\"Feature extractor: {self.feature_extractor}\")\n","\n","#         self.fc = nn.Sequential(\n","#             nn.Dropout(dropout),\n","#             nn.Linear(len_last_layer, n_classes)\n","#         )\n","#         print(f\"Fully connected layer: {self.fc}\")\n","\n","#     @staticmethod\n","#     def _len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs):\n","#         len_last_layer = n_channels * (input_size // (max_pool_size ** 2)) * n_conv_chs\n","#         print(f\"Computed length of last layer - n_channels: {n_channels}, input_size: {input_size}, \"\n","#               f\"max_pool_size: {max_pool_size}, n_conv_chs: {n_conv_chs} -> len_last_layer: {len_last_layer}\")\n","#         return len_last_layer\n","\n","#     def forward(self, x):\n","#         print(f\"Forward pass input: {x.shape}\")\n","        \n","#         if self.n_channels > 1:\n","#             x = self.spatial_conv(x)\n","#             print(f\"After spatial conv: {x.shape}\")\n","#             x = x.transpose(1, 2)\n","#             print(f\"After transpose: {x.shape}\")\n","\n","#         x = self.feature_extractor(x)\n","#         print(f\"After feature extraction: {x.shape}\")\n","\n","#         x = x.flatten(start_dim=1)\n","#         print(f\"After flattening: {x.shape}\")\n","\n","#         x = self.fc(x)\n","#         print(f\"After fully connected layer: {x.shape}\")\n","        \n","#         return x\n"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"ncLv8Dgp7x4s"},"outputs":[],"source":["# hyperperameters\n","dropout=0.75\n","lr=1e-3"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"CCkyhoaA71sv"},"outputs":[],"source":["sfreq = raws[0].info['sfreq']  # Sampling frequency\n","n_channels = raws[0].info['nchan']  # Number of channels\n","\n","model = SleepStagerChambon2018(n_channels, sfreq, n_classes=5,dropout=dropout)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":35,"metadata":{"id":"bYdY92vQHZjE"},"outputs":[],"source":["model = model.to(device)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"fSZtzukY747q"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# Create dataloaders\n","train_batch_size = 128  # Important hyperparameter\n","valid_batch_size = 250  # Can be made as large as what fits in memory; won't impact performance\n","num_workers = 0  # Number of processes to use for the data loading process; 0 is the main Python process\n","\n","loader_train = DataLoader(\n","    train_ds, batch_size=train_batch_size, shuffle=True, num_workers=num_workers)\n","loader_valid = DataLoader(\n","    valid_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)\n","loader_test = DataLoader(\n","    test_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"BWKQtTt_78n7"},"outputs":[],"source":["# functions to carry out our training and validation loops:\n","from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n","\n","def _do_train(model, loader, optimizer, criterion, device, metric):\n","    # training loop\n","    model.train()\n","\n","    train_loss = np.zeros(len(loader))\n","    y_pred_all, y_true_all = [], []\n","    for idx_batch, (batch_x, batch_y) in enumerate(loader):\n","        optimizer.zero_grad()\n","        batch_x = batch_x.to(device=device, dtype=torch.float32)\n","        batch_y = batch_y.to(device=device, dtype=torch.int64)\n","\n","        output = model(batch_x)\n","        loss = criterion(output, batch_y)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n","        y_true_all.append(batch_y.cpu().numpy())\n","\n","        train_loss[idx_batch] = loss.item()\n","\n","    y_pred = np.concatenate(y_pred_all)\n","    y_true = np.concatenate(y_true_all)\n","    perf = metric(y_true, y_pred)\n","\n","    return np.mean(train_loss), perf\n","\n","\n","def _validate(model, loader, criterion, device, metric):\n","    # validation loop\n","    model.eval()\n","\n","    val_loss = np.zeros(len(loader))\n","    y_pred_all, y_true_all = [], []\n","    with torch.no_grad():\n","        for idx_batch, (batch_x, batch_y) in enumerate(loader):\n","            batch_x = batch_x.to(device=device, dtype=torch.float32)\n","            batch_y = batch_y.to(device=device, dtype=torch.int64)\n","            output = model.forward(batch_x)\n","\n","            loss = criterion(output, batch_y)\n","            val_loss[idx_batch] = loss.item()\n","\n","            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n","            y_true_all.append(batch_y.cpu().numpy())\n","\n","    y_pred = np.concatenate(y_pred_all)\n","    y_true = np.concatenate(y_true_all)\n","    perf = metric(y_true, y_pred)\n","\n","    return np.mean(val_loss), perf\n","\n","\n","def train(model, loader_train, loader_valid, optimizer, criterion, n_epochs,\n","          patience, device, metric=None):\n","\n","    best_valid_loss = np.inf\n","    best_model = copy.deepcopy(model)\n","    waiting = 0\n","    history = []\n","\n","    if metric is None:\n","        metric = balanced_accuracy_score\n","\n","    print('epoch \\t train_loss \\t valid_loss \\t train_perf \\t valid_perf')\n","    print('-------------------------------------------------------------------')\n","\n","    for epoch in range(1, n_epochs + 1):\n","        train_loss, train_perf = _do_train(\n","            model, loader_train, optimizer, criterion, device, metric=metric)\n","        valid_loss, valid_perf = _validate(\n","            model, loader_valid, criterion, device, metric=metric)\n","        history.append(\n","            {'epoch': epoch,\n","             'train_loss': train_loss, 'valid_loss': valid_loss,\n","             'train_perf': train_perf, 'valid_perf': valid_perf})\n","\n","        print(f'{epoch} \\t {train_loss:0.4f} \\t {valid_loss:0.4f} '\n","              f'\\t {train_perf:0.4f} \\t {valid_perf:0.4f}')\n","\n","        # model saving\n","        if valid_loss < best_valid_loss:\n","            print(f'best val loss {best_valid_loss:.4f} -> {valid_loss:.4f}')\n","            best_valid_loss = valid_loss\n","            best_model = copy.deepcopy(model)\n","            waiting = 0\n","        else:\n","            waiting += 1\n","\n","        # model early stopping\n","        if waiting >= patience:\n","            print(f'Stop training at epoch {epoch}')\n","            print(f'Best val loss : {best_valid_loss:.4f}')\n","            break\n","\n","    return best_model, history"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# import numpy as np\n","# import copy\n","# from sklearn.metrics import balanced_accuracy_score\n","\n","# def _do_train(model, loader, optimizer, criterion, device, metric):\n","#     # training loop\n","#     model.train()\n","    \n","#     train_loss = np.zeros(len(loader))\n","#     y_pred_all, y_true_all = [], []\n","    \n","#     for idx_batch, (batch_x, batch_y) in enumerate(loader):\n","#         optimizer.zero_grad()\n","        \n","#         # Move to device\n","#         batch_x = batch_x.to(device=device, dtype=torch.float32)\n","#         batch_y = batch_y.to(device=device, dtype=torch.int64)\n","\n","#         output = model(batch_x)\n","#         loss = criterion(output, batch_y)\n","\n","#         # Backpropagation\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n","#         y_true_all.append(batch_y.cpu().numpy())\n","\n","#         train_loss[idx_batch] = loss.item()\n","\n","#         # Print variables for debugging\n","#         print(f\"Batch {idx_batch}: Loss: {loss.item()}, Predictions: {y_pred_all[-1]}, True labels: {y_true_all[-1]}\")\n","\n","#     y_pred = np.concatenate(y_pred_all)\n","#     y_true = np.concatenate(y_true_all)\n","#     perf = metric(y_true, y_pred)\n","\n","#     # Print overall performance metrics\n","#     print(f\"Training - Loss: {np.mean(train_loss)}, Performance: {perf}\")\n","\n","#     return np.mean(train_loss), perf\n","\n","\n","# def _validate(model, loader, criterion, device, metric):\n","#     # validation loop\n","#     model.eval()\n","\n","#     val_loss = np.zeros(len(loader))\n","#     y_pred_all, y_true_all = [], []\n","    \n","#     with torch.no_grad():\n","#         for idx_batch, (batch_x, batch_y) in enumerate(loader):\n","#             batch_x = batch_x.to(device=device, dtype=torch.float32)\n","#             batch_y = batch_y.to(device=device, dtype=torch.int64)\n","#             output = model(batch_x)\n","\n","#             loss = criterion(output, batch_y)\n","#             val_loss[idx_batch] = loss.item()\n","\n","#             y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n","#             y_true_all.append(batch_y.cpu().numpy())\n","\n","#             # Print variables for debugging\n","#             print(f\"Validation Batch {idx_batch}: Loss: {loss.item()}, Predictions: {y_pred_all[-1]}, True labels: {y_true_all[-1]}\")\n","\n","#     y_pred = np.concatenate(y_pred_all)\n","#     y_true = np.concatenate(y_true_all)\n","#     perf = metric(y_true, y_pred)\n","\n","#     # Print overall performance metrics\n","#     print(f\"Validation - Loss: {np.mean(val_loss)}, Performance: {perf}\")\n","\n","#     return np.mean(val_loss), perf\n","\n","\n","# def train(model, loader_train, loader_valid, optimizer, criterion, n_epochs,\n","#           patience, device, metric=None):\n","\n","#     best_valid_loss = np.inf\n","#     best_model = copy.deepcopy(model)\n","#     waiting = 0\n","#     history = []\n","\n","#     if metric is None:\n","#         metric = balanced_accuracy_score\n","\n","#     print('epoch \\t train_loss \\t valid_loss \\t train_perf \\t valid_perf')\n","#     print('-------------------------------------------------------------------')\n","\n","#     for epoch in range(1, n_epochs + 1):\n","#         train_loss, train_perf = _do_train(\n","#             model, loader_train, optimizer, criterion, device, metric=metric)\n","#         valid_loss, valid_perf = _validate(\n","#             model, loader_valid, criterion, device, metric=metric)\n","        \n","#         history.append(\n","#             {'epoch': epoch,\n","#              'train_loss': train_loss, 'valid_loss': valid_loss,\n","#              'train_perf': train_perf, 'valid_perf': valid_perf})\n","\n","#         print(f'{epoch} \\t {train_loss:0.4f} \\t {valid_loss:0.4f} '\n","#               f'\\t {train_perf:0.4f} \\t {valid_perf:0.4f}')\n","\n","#         # model saving\n","#         if valid_loss < best_valid_loss:\n","#             print(f'best val loss {best_valid_loss:.4f} -> {valid_loss:.4f}')\n","#             best_valid_loss = valid_loss\n","#             best_model = copy.deepcopy(model)\n","#             waiting = 0\n","#         else:\n","#             waiting += 1\n","\n","#         # model early stopping\n","#         if waiting >= patience:\n","#             print(f'Stop training at epoch {epoch}')\n","#             print(f'Best val loss : {best_valid_loss:.4f}')\n","#             break\n","\n","#     return best_model, history\n"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"idm6NhhG7_qd"},"outputs":[],"source":["from torch.nn import CrossEntropyLoss\n","from torch.optim import Adam\n","\n","optimizer = Adam(model.parameters(), lr=lr, weight_decay=0)\n","criterion = CrossEntropyLoss(weight=torch.Tensor(class_weights).to(device))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58036,"status":"ok","timestamp":1708444858598,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"un7xn0sX8DXe","outputId":"a4e4b865-cf55-4acb-c4e4-36a9600630cb"},"outputs":[],"source":["n_epochs =10\n","patience =10\n","best_model, history = train(model, loader_train, loader_valid, optimizer, criterion, n_epochs, patience,\n","                                 device, metric=cohen_kappa_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708444586446,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"YikzZxmMKeEb","outputId":"61ec8e4b-6d87-45cc-e2b0-3f064fd29740"},"outputs":[],"source":["best_epoch_index = max(range(len(history)), key=lambda i: history[i]['valid_perf'])\n","best_epoch_info = history[best_epoch_index]\n","best_epoch_performance = best_epoch_info['valid_perf']\n","\n","# Print the results\n","print(f\"Best Epoch Index: {best_epoch_index}\")\n","print(f\"Best Validation Performance: {best_epoch_performance}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjF57YpV8IkV"},"outputs":[],"source":["# Compute test performance\n","\n","best_model.eval()\n","\n","y_pred_all, y_true_all = [], []\n","for batch_x, batch_y in loader_test:\n","    batch_x = batch_x.to(device=device, dtype=torch.float32)\n","    batch_y = batch_y.to(device=device, dtype=torch.int64)\n","    output = model.forward(batch_x)\n","    y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n","    y_true_all.append(batch_y.cpu().numpy())\n","\n","y_pred = np.concatenate(y_pred_all)\n","y_true = np.concatenate(y_true_all)\n","rec_ids = np.concatenate(  # indicates which recording each example comes from\n","    [[i] * len(ds) for i, ds in enumerate(test_ds.datasets)])\n","\n","test_bal_acc = balanced_accuracy_score(y_true, y_pred)\n","test_kappa = cohen_kappa_score(y_true, y_pred)\n","\n","print(f'Test balanced accuracy: {test_bal_acc:0.3f}')\n","print(f'Test Cohen\\'s kappa: {test_kappa:0.3f}')"]},{"cell_type":"code","execution_count":141,"metadata":{"id":"Lle8JpjpAm6h"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(conf_mat, classes_mapping):\n","    ticks = [key for key in classes_mapping.keys()]\n","    tick_labels = classes_mapping.values()\n","\n","    fig, ax = plt.subplots(figsize=(6, 6))\n","    im = ax.imshow(conf_mat, cmap='Greens')\n","\n","    ax.set_yticks(ticks)\n","    ax.set_yticklabels(tick_labels)\n","    ax.set_xticks(ticks)\n","    ax.set_xticklabels(tick_labels)\n","    ax.set_ylabel('True label')\n","    ax.set_xlabel('Predicted label')\n","    ax.set_title('Confusion matrix')\n","\n","    for i in range(len(ticks)):\n","        for j in range(len(ticks)):\n","            text = ax.text(\n","                j, i, conf_mat[i, j], ha='center', va='center', color='k')\n","\n","    fig.colorbar(im, ax=ax, fraction=0.05, label='# examples')\n","    fig.tight_layout()\n","\n","    return fig, ax"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Define metrics and their names\n","metrics = ['Balanced Accuracy', 'Cohen\\'s Kappa']\n","values = [test_bal_acc, test_kappa]\n","errors = [0.02, 0.02]  # Example error values; replace with actual if available\n","\n","# Create the bar plot\n","fig, ax = plt.subplots(figsize=(10, 6))\n","bars = ax.bar(metrics, values, yerr=errors, capsize=5, color=['skyblue', 'lightcoral'])\n","\n","# Add labels and title\n","ax.set_xlabel('Metric')\n","ax.set_ylabel('Score')\n","ax.set_title('Test Performance Metrics Comparison')\n","ax.set_ylim(0, 1)  # Set y-axis limit from 0 to 1 for percentage metrics\n","\n","# Adding value labels on top of bars\n","for bar in bars:\n","    yval = bar.get_height()\n","    ax.text(bar.get_x() + bar.get_width()/2, yval + 0.02, f'{yval:.3f}', ha='center', va='bottom')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"executionInfo":{"elapsed":4058,"status":"ok","timestamp":1708444863433,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"EK5eiTbQAsDR","outputId":"b349076c-4c9a-485e-c62a-c9aa1f5291e2"},"outputs":[],"source":["conf_mat = confusion_matrix(y_true, y_pred)\n","plot_confusion_matrix(conf_mat, classes_mapping);"]},{"cell_type":"code","execution_count":144,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(conf_mat, classes_mapping):\n","    ticks = list(classes_mapping.keys())\n","    tick_labels = classes_mapping.values()\n","\n","    fig, ax = plt.subplots(figsize=(6, 6))\n","    im = ax.imshow(conf_mat, cmap='Reds')\n","\n","    ax.set_yticks(ticks)\n","    ax.set_yticklabels(tick_labels)\n","    ax.set_xticks(ticks)\n","    ax.set_xticklabels(tick_labels)\n","    ax.set_ylabel('True label')\n","    ax.set_xlabel('Predicted label')\n","    ax.set_title('Confusion matrix')\n","\n","    for i in range(len(ticks)):\n","        for j in range(len(ticks)):\n","            text = ax.text(\n","                j, i, conf_mat[i, j], ha='center', va='center', color='k')\n","\n","    fig.colorbar(im, ax=ax, fraction=0.05, label='')\n","    fig.tight_layout()\n","\n","    return fig, ax"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conf_mat = confusion_matrix(y_true, y_pred)\n","plot_confusion_matrix(conf_mat, classes_mapping);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"executionInfo":{"elapsed":57,"status":"ok","timestamp":1708444863434,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"xykWve0bA0Sx","outputId":"45f40eeb-f080-42f5-ce41-b787ea059203"},"outputs":[],"source":["import seaborn as sns\n","x_axis_labels=[\"W\", \"N1\", 'N2','N3','R']\n","y_axis_labels =[\"W\", 'N1', 'N2','N3','R']\n","\n","ax = sns.heatmap(conf_mat/conf_mat.sum(axis=1)[:, np.newaxis], annot=True,  cmap='Greens',xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n","ax.set_yticklabels(ax.get_yticklabels(), rotation = 0, fontsize = 10)\n","ax.set_title('Confusion Matrix with precentage \\n\\n');\n","ax.set_xlabel('\\nPredicted label')\n","ax.set_ylabel('True label');\n","\n","\n","## Display the visualization of the Confusion Matrix.\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1708444863436,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"_MyZHUtPA9eO","outputId":"4678106a-ea11-4dd1-d8b2-d901230dac23"},"outputs":[],"source":["from sklearn import metrics\n","target_names = ['W', 'N1', 'N2','N3','R']\n","print(metrics.classification_report(y_true, y_pred, target_names=target_names))"]},{"cell_type":"code","execution_count":148,"metadata":{},"outputs":[],"source":["y_pred = np.concatenate(y_pred_all)\n","y_true = np.concatenate(y_true_all)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def evaluate_model(model, loader, device):\n","    model.eval()  # Set model to evaluation mode\n","    true_labels = []\n","    predictions = []\n","    with torch.no_grad():  # No need to track gradients\n","        for batch_x, batch_y in loader:\n","            batch_x = batch_x.to(device=device, dtype=torch.float32)\n","            output = model(batch_x)\n","            probs = F.softmax(output, dim=1)  # Convert logits to probabilities\n","            predictions.append(probs.cpu().numpy())\n","            true_labels.append(batch_y.cpu().numpy())\n","\n","    predictions = np.concatenate(predictions)\n","    true_labels = np.concatenate(true_labels)\n","    return true_labels, predictions\n","\n","# After training your model, evaluate it to get true labels and predicted probabilities\n","y_true, y_pred_probs = evaluate_model(best_model, loader_test, device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","from itertools import cycle\n","import matplotlib.pyplot as plt\n","\n","def plot_multiclass_roc_auc(y_true, y_score, n_classes):\n","    # Compute ROC curve and ROC area for each class\n","    fpr = dict()\n","    tpr = dict()\n","    roc_auc = dict()\n","    for i in range(n_classes):\n","        fpr[i], tpr[i], _ = roc_curve(y_true == i, y_score[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","    # Plot ROC curve for each class\n","    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n","    for i, color in zip(range(n_classes), colors):\n","        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n","                 label='ROC curve of class {0} (area = {1:0.2f})'\n","                 ''.format(i, roc_auc[i]))\n","\n","    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver operating characteristic')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","# Call the plotting function with the number of classes\n","plot_multiclass_roc_auc(y_true, y_pred_probs, n_classes=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Extracting training and validation performance\n","epochs = [x['epoch'] for x in history]\n","train_perfs = [x['train_perf'] for x in history]\n","valid_perfs = [x['valid_perf'] for x in history]\n","\n","# Plotting\n","plt.figure(figsize=(10, 5))\n","plt.plot(epochs, train_perfs, label='Training Accuracy')\n","plt.plot(epochs, valid_perfs, label='Validation Accuracy', linestyle='--')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')  # Adjust this label if you are using a metric other than accuracy\n","plt.title('Accuracy vs Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def train_and_plot(model, loader_train, loader_valid, optimizer, criterion, n_epochs, patience, device, metric=None):\n","    best_valid_loss = np.inf\n","    best_model = copy.deepcopy(model)\n","    waiting = 0\n","    history = []\n","\n","    if metric is None:\n","        metric = balanced_accuracy_score\n","\n","    for epoch in range(1, n_epochs + 1):\n","        train_loss, train_perf = _do_train(\n","            model, loader_train, optimizer, criterion, device, metric=metric)\n","        valid_loss, valid_perf = _validate(\n","            model, loader_valid, criterion, device, metric=metric)\n","        history.append({\n","            'epoch': epoch,\n","            'train_loss': train_loss, 'valid_loss': valid_loss,\n","            'train_perf': train_perf, 'valid_perf': valid_perf})\n","\n","        print(f'{epoch} \\t {train_loss:.4f} \\t {valid_loss:.4f} \\t {train_perf:.4f} \\t {valid_perf:.4f}')\n","\n","        # Model improvement check\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            best_model = copy.deepcopy(model)\n","            waiting = 0\n","        else:\n","            waiting += 1\n","\n","        # Early stopping check\n","        if waiting >= patience:\n","            print(f'Stop training at epoch {epoch}')\n","            print(f'Best val loss: {best_valid_loss:.4f}')\n","            break\n","\n","    # Accuracy vs Epoch Plot\n","    epochs = [x['epoch'] for x in history]\n","    train_accs = [x['train_perf'] for x in history]\n","    valid_accs = [x['valid_perf'] for x in history]\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(epochs, train_accs, label='Train Accuracy')\n","    plt.plot(epochs, valid_accs, label='Validation Accuracy', linestyle='--')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')  # Update this if you use metrics other than accuracy\n","    plt.title('Accuracy vs Epoch During Training')\n","    plt.legend()\n","    plt.show()\n","\n","    return best_model, history\n","\n","# Update model training call\n","best_model, training_history = train_and_plot(model, loader_train, loader_valid, optimizer, criterion, n_epochs, patience, device, metric=cohen_kappa_score)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.express as px\n","\n","# Create Radar Chart\n","fig = px.line_polar(df, r='Precision', theta='Class', line_close=True, title='Radar Chart for Precision')\n","fig.add_scatterpolar(r=df['Recall'], theta=df['Class'], mode='lines', name='Recall')\n","fig.add_scatterpolar(r=df['F1 Score'], theta=df['Class'], mode='lines', name='F1 Score')\n","\n","# Update layout\n","fig.update_layout(\n","    polar=dict(\n","        radialaxis=dict(visible=True),\n","        angularaxis=dict(visible=True)\n","        \n","    )\n",")\n","\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Extracted values from your classification report for 5 stages\n","precision = [0.77, 0.85, 0.90, 0.93, 0.80]  # Example precision values for W, N1, N2, N3, R\n","recall = [0.99, 0.70, 0.75, 0.80, 0.60]     # Example recall values for W, N1, N2, N3, R\n","f1_score = [0.86, 0.77, 0.82, 0.86, 0.68]   # Example F1 score values for W, N1, N2, N3, R\n","classes = ['W', 'N1', 'N2', 'N3', 'R']\n","\n","# Plotting\n","fig, ax = plt.subplots(figsize=(12, 6))\n","bar_width = 0.25\n","index = np.arange(len(classes))\n","\n","# Plot bars for each metric\n","bar1 = ax.bar(index, precision, bar_width, label='Precision', color='b')\n","bar2 = ax.bar(index + bar_width, recall, bar_width, label='Recall', color='g')\n","bar3 = ax.bar(index + 2 * bar_width, f1_score, bar_width, label='F1 Score', color='r')\n","\n","# Add aesthetics\n","ax.set_xlabel('Sleep Stages')\n","ax.set_ylabel('Scores')\n","ax.set_title('Precision, Recall, and F1 Score for Each Class')\n","ax.set_xticks(index + bar_width)\n","ax.set_xticklabels(classes)\n","\n","# Change legend location to right outside the chart\n","ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n","\n","# Helper function to attach a text label above each bar\n","def autolabel(bars):\n","    for bar in bars:\n","        height = bar.get_height()\n","        ax.annotate('{}'.format(round(height, 2)),\n","                    xy=(bar.get_x() + bar.get_width() / 2, height),\n","                    xytext=(0, 3),  # 3 points vertical offset\n","                    textcoords=\"offset points\",\n","                    ha='center', va='bottom')\n","\n","autolabel(bar1)\n","autolabel(bar2)\n","autolabel(bar3)\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"elapsed":1545,"status":"ok","timestamp":1708444893012,"user":{"displayName":"MIT PATEL","userId":"00691351102091516739"},"user_tz":-330},"id":"q6ToKrocBBbE","outputId":"cba15a55-8743-472a-eb45-13da7961992a"},"outputs":[],"source":["# Plot hypnogram for one recording\n","\n","mask = rec_ids == 3  # pick a recording number\n","\n","t = np.arange(len(y_true[mask])) * 30 / 3600\n","\n","fig, ax = plt.subplots(figsize=(12, 3))\n","ax.plot(t, y_true[mask], label='True')\n","ax.plot(t, y_pred[mask], alpha=0.7, label='Predicted')\n","ax.set_yticks([0, 1, 2, 3, 4])\n","ax.set_yticklabels(['W', 'N1', 'N2', 'N3', 'R'])\n","ax.set_xlabel('Time (h)')\n","ax.set_title('Hypnogram')\n","ax.legend();"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Extract history information\n","epochs = [entry['epoch'] for entry in history]\n","train_losses = [entry['train_loss'] for entry in history]\n","valid_losses = [entry['valid_loss'] for entry in history]\n","train_perfs = [entry['train_perf'] for entry in history]\n","valid_perfs = [entry['valid_perf'] for entry in history]\n","\n","# Plotting\n","plt.figure(figsize=(12, 5))\n","\n","# Loss plot\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs, train_losses, label='Train')\n","plt.plot(epochs, valid_losses, label='Validation')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Performance plot\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs, train_perfs, label='Train')\n","plt.plot(epochs, valid_perfs, label='Validation')\n","plt.title('Training and Validation Performance')\n","plt.xlabel('Epochs')\n","plt.ylabel('Performance')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Add this code after computing y_true and y_pred\n","import random\n","\n","# Randomly select indices for visualization\n","sample_indices = random.sample(range(len(y_true)), min(5, len(y_true)))\n","\n","# Visualize predicted vs true labels\n","for idx in sample_indices:\n","    print(f\"Example {idx + 1} - True: {classes_mapping[y_true[idx]]}, Predicted: {classes_mapping[y_pred[idx]]}\")\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPz5dCAxngW1JaISzKK9qFn","gpuType":"T4","provenance":[{"file_id":"1TYolps4OaugUhEFj8cVxW9dGoEoS-lIV","timestamp":1708441303012},{"file_id":"139W9eRpHIiPhfEl98D2njS5UZ1E1HjRl","timestamp":1708323551932},{"file_id":"1P3esjOrzazvNvICasYFn82gvYqa43qH3","timestamp":1708320811424}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
