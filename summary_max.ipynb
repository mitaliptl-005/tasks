{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define Constants\n",
    "\n",
    "W = 0\n",
    "N1 = 1\n",
    "N2 = 2\n",
    "N3 = 3\n",
    "REM = 4\n",
    "classes = ['W', 'N1', 'N2', 'N3', 'REM']\n",
    "n_classes = len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Functions\n",
    "\n",
    "def evaluate_metrics(cm):\n",
    "    cm = cm.astype(np.float32)\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)\n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    PPV = TP / (TP + FP)\n",
    "    NPV = TN / (TN + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "    FDR = FP / (TP + FP)\n",
    "\n",
    "    ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "    ACC_macro = np.mean(ACC)\n",
    "\n",
    "    F1 = (2 * PPV * TPR) / (PPV + TPR)\n",
    "    F1_macro = np.mean(F1)\n",
    "\n",
    "    return ACC_macro, ACC, F1_macro, F1, TPR, TNR, PPV\n",
    "\n",
    "def print_performance(cm, y_true=[], y_pred=[]):\n",
    "    tp = np.diagonal(cm).astype(float)\n",
    "    tpfp = np.sum(cm, axis=0).astype(float) \n",
    "    tpfn = np.sum(cm, axis=1).astype(float) \n",
    "    acc = np.sum(tp) / np.sum(cm)\n",
    "    precision = tp / tpfp\n",
    "    recall = tp / tpfn\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    FP = cm.sum(axis=0).astype(float) - np.diag(cm)\n",
    "    FN = cm.sum(axis=1).astype(float) - np.diag(cm)\n",
    "    TP = np.diag(cm).astype(float)\n",
    "    TN = cm.sum().astype(float) - (FP + FN + TP)\n",
    "    specificity = TN / (TN + FP) \n",
    "\n",
    "    mf1 = np.mean(f1)\n",
    "\n",
    "    overall_accuracy = np.mean(y_true == y_pred) if len(y_true) > 0 else acc\n",
    "\n",
    "    return {\n",
    "        'accuracy': overall_accuracy,\n",
    "        'macro_f1': mf1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define Performance Overall Function\n",
    "\n",
    "def perf_overall(data_dir):\n",
    "    allfiles = os.listdir(data_dir)\n",
    "    outputfiles = [os.path.join(data_dir, f) for f in allfiles if re.match(r\"^output_.+\\d+\\.npz\", f)]\n",
    "    outputfiles.sort()\n",
    "\n",
    "    max_accuracy = -1\n",
    "    max_accuracy_file = \"\"\n",
    "\n",
    "    for fpath in outputfiles:\n",
    "        with np.load(fpath) as f:\n",
    "            if len(f[\"y_true\"].shape) == 1:\n",
    "                if len(f[\"y_true\"]) < 10:\n",
    "                    f_y_true = np.hstack(f[\"y_true\"])\n",
    "                    f_y_pred = np.hstack(f[\"y_pred\"])\n",
    "                else:\n",
    "                    f_y_true = f[\"y_true\"]\n",
    "                    f_y_pred = f[\"y_pred\"]\n",
    "            else:\n",
    "                f_y_true = f[\"y_true\"].flatten()\n",
    "                f_y_pred = f[\"y_pred\"].flatten()\n",
    "\n",
    "            cm = confusion_matrix(f_y_true, f_y_pred, labels=[0, 1, 2, 3, 4])\n",
    "            perf = print_performance(cm, f_y_true, f_y_pred)\n",
    "\n",
    "            if perf['accuracy'] > max_accuracy:\n",
    "                max_accuracy = perf['accuracy']\n",
    "                max_accuracy_file = fpath\n",
    "\n",
    "    print(f\"File with maximum accuracy: {max_accuracy_file}\")\n",
    "    print(f\"Maximum accuracy: {max_accuracy:.4f}\")\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for fpath in outputfiles:\n",
    "        with np.load(fpath) as f:\n",
    "            if len(f[\"y_true\"].shape) == 1:\n",
    "                if len(f[\"y_true\"]) < 10:\n",
    "                    f_y_true = np.hstack(f[\"y_true\"])\n",
    "                    f_y_pred = np.hstack(f[\"y_pred\"])\n",
    "                else:\n",
    "                    f_y_true = f[\"y_true\"]\n",
    "                    f_y_pred = f[\"y_pred\"]\n",
    "            else:\n",
    "                f_y_true = f[\"y_true\"].flatten()\n",
    "                f_y_pred = f[\"y_pred\"].flatten()\n",
    "\n",
    "            y_true.extend(f_y_true)\n",
    "            y_pred.extend(f_y_pred)\n",
    "\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    sio.savemat('con_matrix_sleep.mat', {'y_true': y_true, 'y_pred': y_pred})\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(n_classes))\n",
    "    acc = np.mean(y_true == y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    print(\"Overall Performance:\")\n",
    "    print(f\"Maximum accuracy: {max_accuracy:.4f}\")\n",
    "    print(f\"Macro-F1 score: {mf1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with maximum accuracy: ./outputs_2013/outputs_eeg_fpz_cz\\output_fold6.npz\n",
      "Maximum accuracy: 0.9022\n",
      "Overall Performance:\n",
      "Maximum accuracy: 0.9022\n",
      "Macro-F1 score: 0.7966\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Main Function and Execute\n",
    "\n",
    "# In Jupyter Notebook, the command line arguments are not used.\n",
    "# Instead, directly call the function with the desired directory path.\n",
    "\n",
    "data_dir = \"./outputs_2013/outputs_eeg_fpz_cz\"  # Set your data directory here\n",
    "perf_overall(data_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
